import streamlit as st
import os
import requests
import asyncio
import edge_tts
import json
import random
import gc # åƒåœ¾å›æ”¶æ©Ÿåˆ¶
import google.generativeai as genai
from moviepy.editor import VideoFileClip, AudioFileClip, ImageClip, CompositeVideoClip, concatenate_videoclips, ColorClip
from PIL import Image, ImageDraw, ImageFont
import numpy as np

# ================= é›²ç«¯è¨­å®šå€ =================
st.set_page_config(page_title="AI çŸ­å½±éŸ³å·¥å»  (è¼•é‡ç‰ˆ)", page_icon="âš¡")

# ğŸ“‰ è¨­å®šå½±ç‰‡è§£æåº¦ (540x960 çœè¨˜æ†¶é«”ï¼Œé˜²æ­¢ç•¶æ©Ÿ)
VIDEO_W, VIDEO_H = 540, 960 

# ğŸ§¹ æ¸…ç†å­—é«”
if os.path.exists("NotoSansTC-Bold.otf"):
    try:
        os.remove("NotoSansTC-Bold.otf")
    except:
        pass

def get_font(size=30):
    return ImageFont.load_default()

# ğŸ§  AI å¯«è…³æœ¬
def generate_script_from_ai(api_key, topic, duration_sec):
    genai.configure(api_key=api_key)
    est_sentences = int(int(duration_sec) / 5) # ç¨å¾®æ¸›å°‘å¥å­æ•¸é‡ï¼Œæ¸›è¼•è² æ“”
    if est_sentences < 3: est_sentences = 3
    
    models_to_try = ['gemini-flash-latest', 'gemini-2.0-flash', 'gemini-pro-latest']
    
    for model_name in models_to_try:
        try:
            model = genai.GenerativeModel(model_name)
            prompt = f"""
            ä½ æ˜¯ä¸€å€‹çŸ­å½±éŸ³è…³æœ¬å°ˆå®¶ã€‚è«‹æ ¹æ“šä¸»é¡Œã€Œ{topic}ã€å¯«å‡ºä¸€å€‹çŸ­å½±éŸ³è…³æœ¬ã€‚
            ã€è¦æ ¼ã€‘ï¼šå½±ç‰‡é•·åº¦ {duration_sec} ç§’ï¼Œè«‹æä¾› {est_sentences} å€‹åˆ†é¡å¥å­ã€‚
            ã€è¦æ±‚ã€‘ï¼šæ¯å¥ 15-20 å­—ï¼Œæ­é…ä¸€å€‹è‹±æ–‡æœå°‹å–®å­— (Keyword)ã€‚
            ã€æ ¼å¼ã€‘ï¼šè«‹åªå›å‚³ç´” JSON é™£åˆ—ï¼Œä¸è¦æœ‰ markdown ç¬¦è™Ÿï¼š
            [
                {{"text": "ç¬¬ä¸€å¥æ—ç™½...", "keyword": "Keyword1"}},
                {{"text": "ç¬¬äºŒå¥æ—ç™½...", "keyword": "Keyword2"}}
            ]
            """
            response = model.generate_content(prompt)
            clean_text = response.text.replace("```json", "").replace("```", "").strip()
            return json.loads(clean_text)
        except:
            continue
    return None

# ğŸ“¥ ä¸‹è¼‰å½±ç‰‡
def download_video(api_key, query, filename):
    url = "https://api.pexels.com/videos/search"
    headers = {"Authorization": api_key}
    params = {"query": query, "per_page": 1, "orientation": "portrait"}
    try:
        r = requests.get(url, headers=headers, params=params, timeout=5)
        if r.status_code == 200:
            data = r.json()
            if data.get('videos'):
                video_url = data['videos'][0]['video_files'][0]['link']
                v_data = requests.get(video_url).content
                with open(filename, 'wb') as f:
                    f.write(v_data)
                return True
    except:
        pass
    return False

# ğŸ—£ï¸ TTS
def run_tts(text, filename, voice, rate):
    rate_str = f"{int((rate - 1.0) * 100):+d}%"
    async def _tts():
        communicate = edge_tts.Communicate(text, voice, rate=rate_str)
        await communicate.save(filename)
    try:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(_tts())
        loop.close()
        return True
    except:
        return False

# ğŸ–¼ï¸ å­—å¹•åœ–ç‰‡
def create_text_image(text, width, height):
    try:
        img = Image.new('RGBA', (width, height), (0, 0, 0, 0))
        draw = ImageDraw.Draw(img)
        font = get_font(30) # å­—é«”å°ä¸€é»é…åˆè§£æåº¦
        
        text_len = len(text) * 15 
        x = (width - text_len) / 2
        if x < 10: x = 10
        y = height - 150
        
        draw.text((x+2, y+2), text, font=font, fill="black")
        draw.text((x, y), text, font=font, fill="white")
        return np.array(img)
    except:
        return np.array(Image.new('RGBA', (width, height), (0, 0, 0, 0)))

# --- ä¸»ç¨‹å¼ ---
st.title("âš¡ AI çŸ­å½±éŸ³å·¥å»  (è¼•é‡ç‰ˆ)")

with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    gemini_key = st.text_input("Gemini Key", type="password") or st.secrets.get("GEMINI_KEY", "")
    pexels_key = st.text_input("Pexels Key", type="password") or st.secrets.get("PEXELS_KEY", "")
    voice_option = st.selectbox("é…éŸ³", ("å¥³è² - æ›‰è‡»", "ç”·è² - é›²å“²"))
    voice_role = "zh-TW-HsiaoChenNeural" if "å¥³è²" in voice_option else "zh-TW-YunJheNeural"
    speech_rate = st.slider("èªé€Ÿ", 0.5, 2.0, 1.2, 0.1)
    duration = st.slider("ç§’æ•¸", 30, 300, 45, 10)

topic = st.text_input("ğŸ’¡ ä¸»é¡Œ", value="é£›æ©Ÿçš„èµ·æº")

if st.button("ğŸš€ ç”Ÿæˆå½±ç‰‡ (ä½è² è¼‰æ¨¡å¼)", type="primary"):
    if not gemini_key or not pexels_key:
        st.error("âŒ ç¼º Key")
        st.stop()
        
    status = st.status("ğŸ§  å•Ÿå‹•è¼•é‡å¼•æ“...", expanded=True)
    
    script_data = generate_script_from_ai(gemini_key, topic, duration)
    if not script_data:
        status.update(label="âŒ åŠ‡æœ¬å¤±æ•—", state="error")
        st.stop()
    
    status.write(f"âœ… åŠ‡æœ¬å®Œæˆï¼å…± {len(script_data)} å¥")
    progress_bar = st.progress(0)
    clips = []
    
    for i, data in enumerate(script_data):
        status.write(f"è£½ä½œç‰‡æ®µ {i+1}/{len(script_data)}: {data['keyword']}...")
        
        safe_kw = "".join([c for c in data['keyword'] if c.isalnum()])
        v_file = f"video_{safe_kw}.mp4"
        a_file = f"temp_{i}.mp3"
        
        download_video(pexels_key, data['keyword'], v_file)
        run_tts(data['text'], a_file, voice_role, speech_rate)
        
        try:
            # 1. è²éŸ³è™•ç†
            a_clip = None
            try:
                if os.path.exists(a_file) and os.path.getsize(a_file) > 100:
                    a_clip = AudioFileClip(a_file)
            except:
                pass 
            
            # 2. å½±ç‰‡è™•ç† (é—œéµï¼šä½¿ç”¨è¼ƒå°çš„è§£æåº¦)
            try:
                if os.path.exists(v_file) and os.path.getsize(v_file) > 1000:
                    # ç¸®å°åˆ° 540x960ï¼Œé€™æœƒå¤§å¹…æ¸›å°‘è¨˜æ†¶é«”æ¶ˆè€—ï¼
                    v_clip = VideoFileClip(v_file).resize(newsize=(VIDEO_W, VIDEO_H))
                else:
                    raise Exception("Video bad")
            except:
                dur = a_clip.duration if a_clip else 3
                v_clip = ColorClip(size=(VIDEO_W, VIDEO_H), color=(0,0,0), duration=dur)

            # 3. åˆæˆèˆ‡æ¸…ç†
            final_dur = a_clip.duration if a_clip else v_clip.duration
            
            # ç¢ºä¿ä¸æœƒéé•·
            if final_dur > 10: final_dur = 10 

            if v_clip.duration < final_dur:
                v_clip = v_clip.loop(duration=final_dur)
            else:
                v_clip = v_clip.subclip(0, final_dur)
            
            if a_clip:
                v_clip = v_clip.set_audio(a_clip)

            try:
                txt_img = create_text_image(data['text'], VIDEO_W, VIDEO_H)
                txt_clip = ImageClip(txt_img).set_duration(final_dur)
                clips.append(CompositeVideoClip([v_clip, txt_clip]))
            except:
                clips.append(v_clip)
            
            # ğŸ§¹ã€é—œéµã€‘å¼·åˆ¶å›æ”¶è¨˜æ†¶é«”ï¼Œé˜²æ­¢ç•¶æ©Ÿ
            del v_clip
            del a_clip
            if 'txt_clip' in locals(): del txt_clip
            gc.collect() 
                
        except Exception as e:
            print(f"âŒ Skip: {e}")
            continue
        
        progress_bar.progress((i + 1) / len(script_data))
    
    if clips:
        status.write("ğŸ¬ æ­£åœ¨è¼•é‡åˆæˆ...")
        try:
            # ä½¿ç”¨ compose æ–¹å¼åˆæˆï¼Œæ¯”è¼ƒçœè¨˜æ†¶é«”
            final = concatenate_videoclips(clips, method="compose")
            output_name = f"result_{random.randint(1000,9999)}.mp4"
            # ä½¿ç”¨ fast é è¨­ï¼ŒåŠ å¿«é€Ÿåº¦
            final.write_videofile(output_name, fps=24, codec='libx264', audio_codec='aac', preset='ultrafast')
            status.update(label="âœ¨ æˆåŠŸäº†ï¼", state="complete")
            st.balloons()
            st.video(output_name)
        except Exception as e:
             st.error(f"åˆæˆå¤±æ•—: {e}")
    else:
        status.update(label="âŒ å¤±æ•—", state="error")